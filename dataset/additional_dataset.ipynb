{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e956d2d9-c60d-43c6-9846-ab41ee99a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71743428-f099-4821-9dc9-29516e5ee4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsad_file_path = \"train.csv\" \n",
    "tsad_df = pd.read_csv(tsad_file_path, usecols=['textID', 'text', 'sentiment'], encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87025754-874f-4d15-90e6-c0ace8432fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsad_df = tsad_df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e56a945-72a5-4784-be32-6aeeed628d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral     11117\n",
       "positive     8582\n",
       "negative     7781\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsad_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "695bc961-e643-42da-b3a9-d50fdfc4967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_n = int(50001/3 - (tsad_df['sentiment'] == \"positive\").sum())\n",
    "neg_n = int(50001/3 - (tsad_df['sentiment'] == \"negative\").sum())\n",
    "neu_n = int(50001/3 - (tsad_df['sentiment'] == \"neutral\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281775e7-8ca7-4ebf-af7c-eaad1b98921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8085 8886 5550\n"
     ]
    }
   ],
   "source": [
    "print(pos_n, neg_n, neu_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3788d89e-a96e-4bc6-816f-85112a6861fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_path = \"training.1600000.processed.noemoticon.csv\"\n",
    "additional_df = pd.read_csv(additional_path, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac55392-0457-4478-a350-9ef7f7ed46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_df.columns = additional_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b6fcfc-f4d6-4e93-b7f2-1a2366039f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity of tweet</th>\n",
       "      <th>id of the tweet</th>\n",
       "      <th>date of the tweet</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text of the tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity of tweet  id of the tweet             date of the tweet     query  \\\n",
       "0                  0       1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1                  0       1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2                  0       1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3                  0       1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4                  0       1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "\n",
       "            user                                  text of the tweet  \n",
       "0  scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "1       mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "2        ElleCTF    my whole body feels itchy and like its on fire   \n",
       "3         Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "4       joy_wolf                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05bcd4de-4705-452e-984f-15806c07d8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate text values: 12440\n"
     ]
    }
   ],
   "source": [
    "duplicate_text_count = additional_df['text of the tweet'].duplicated().sum()\n",
    "print(f\"Number of duplicate text values: {duplicate_text_count}\")\n",
    "\n",
    "additional_df = additional_df.drop_duplicates(subset=['text of the tweet'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff90e8f3-33e7-465c-8a34-b3370ffabb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  cb774db0d1                I`d have responded, if I were going   neutral\n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2  088c60f138                          my boss is bullying me...  negative\n",
       "3  9642c003ef                     what interview! leave me alone  negative\n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...  negative"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36426f3b-0c2e-4531-a9c5-406f8cfb8537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['text', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "861139e3-5d32-4700-9623-e4dd00317be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = tsad_df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a993c48-0863-4cbd-83f5-c022f38c4e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shawn\\anaconda3\\envs\\cs4248\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \n",
    "    encoded_input = tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    return config.id2label[ranking[0]].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efb205-c200-432e-8a57-db6c23b01065",
   "metadata": {},
   "source": [
    "# Get more positive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "537141c2-3024-4e10-bdc4-53e512eb8a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = additional_df[additional_df['polarity of tweet'] == 4].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce41ba4b-8b54-4491-80a5-918badcd01b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on row 100\n",
      "Working on row 200\n",
      "Working on row 300\n",
      "Working on row 400\n",
      "Working on row 500\n",
      "Working on row 600\n",
      "Working on row 700\n",
      "Working on row 800\n",
      "Working on row 900\n",
      "Working on row 1000\n",
      "Working on row 1100\n",
      "Working on row 1200\n",
      "Working on row 1300\n",
      "Working on row 1400\n",
      "Working on row 1500\n",
      "Working on row 1600\n",
      "Working on row 1700\n",
      "Working on row 1800\n",
      "Working on row 1900\n",
      "Working on row 2000\n",
      "Working on row 2100\n",
      "Working on row 2200\n",
      "Working on row 2300\n",
      "Working on row 2400\n",
      "Working on row 2500\n",
      "Working on row 2600\n",
      "Working on row 2700\n",
      "Working on row 2800\n",
      "Working on row 2900\n",
      "Working on row 3000\n",
      "Working on row 3100\n",
      "Working on row 3200\n",
      "Working on row 3300\n",
      "Working on row 3400\n",
      "Working on row 3500\n",
      "Working on row 3600\n",
      "Working on row 3700\n",
      "Working on row 3800\n",
      "Working on row 3900\n",
      "Working on row 4000\n",
      "Working on row 4100\n",
      "Working on row 4200\n",
      "Working on row 4300\n",
      "Working on row 4400\n",
      "Working on row 4500\n",
      "Working on row 4600\n",
      "Working on row 4700\n",
      "Working on row 4800\n",
      "Working on row 4900\n",
      "Working on row 5000\n",
      "Working on row 5100\n",
      "Working on row 5200\n",
      "Working on row 5300\n",
      "Working on row 5400\n",
      "Working on row 5500\n",
      "Working on row 5600\n",
      "Working on row 5700\n",
      "Working on row 5800\n",
      "Working on row 5900\n",
      "Working on row 6000\n",
      "Working on row 6100\n",
      "Working on row 6200\n",
      "Working on row 6300\n",
      "Working on row 6400\n",
      "Working on row 6500\n",
      "Working on row 6600\n",
      "Working on row 6700\n",
      "Working on row 6800\n",
      "Working on row 6900\n",
      "Working on row 7000\n",
      "Working on row 7100\n",
      "Working on row 7200\n",
      "Working on row 7300\n",
      "Working on row 7400\n",
      "Working on row 7500\n",
      "Working on row 7600\n",
      "Working on row 7700\n",
      "Working on row 7800\n",
      "Working on row 7900\n",
      "Working on row 8000\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for i in range(pos_n):\n",
    "    if (i + 1)%100 == 0:\n",
    "        print(\"Working on row\", i + 1)\n",
    "    text = None\n",
    "    while True:\n",
    "        text = pos_df.iloc[idx]['text of the tweet']\n",
    "        # text = re.sub(r\"^(@\\w+\\s+)+\", \"\", text)\n",
    "        if text.strip() == \"\" or text in all_text:\n",
    "            idx += 1\n",
    "            continue\n",
    "        if get_sentiment(text) == 'positive':\n",
    "            idx += 1\n",
    "            break\n",
    "        else:\n",
    "            idx += 1\n",
    "            continue\n",
    "    df.loc[len(df)] = [text, 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "233dbdbd-9ebc-41e2-b5b1-ba13152668ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"additional_ds.csv\", encoding=\"latin1\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c1305-c3c1-4fc2-b1fa-f213326ae0c5",
   "metadata": {},
   "source": [
    "# Get more negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f1dcadb-5ba4-499c-abb3-a9651db182ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = additional_df[additional_df['polarity of tweet'] == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a299175-9f34-4efa-a04c-aff6743b48d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on row 100\n",
      "Working on row 200\n",
      "Working on row 300\n",
      "Working on row 400\n",
      "Working on row 500\n",
      "Working on row 600\n",
      "Working on row 700\n",
      "Working on row 800\n",
      "Working on row 900\n",
      "Working on row 1000\n",
      "Working on row 1100\n",
      "Working on row 1200\n",
      "Working on row 1300\n",
      "Working on row 1400\n",
      "Working on row 1500\n",
      "Working on row 1600\n",
      "Working on row 1700\n",
      "Working on row 1800\n",
      "Working on row 1900\n",
      "Working on row 2000\n",
      "Working on row 2100\n",
      "Working on row 2200\n",
      "Working on row 2300\n",
      "Working on row 2400\n",
      "Working on row 2500\n",
      "Working on row 2600\n",
      "Working on row 2700\n",
      "Working on row 2800\n",
      "Working on row 2900\n",
      "Working on row 3000\n",
      "Working on row 3100\n",
      "Working on row 3200\n",
      "Working on row 3300\n",
      "Working on row 3400\n",
      "Working on row 3500\n",
      "Working on row 3600\n",
      "Working on row 3700\n",
      "Working on row 3800\n",
      "Working on row 3900\n",
      "Working on row 4000\n",
      "Working on row 4100\n",
      "Working on row 4200\n",
      "Working on row 4300\n",
      "Working on row 4400\n",
      "Working on row 4500\n",
      "Working on row 4600\n",
      "Working on row 4700\n",
      "Working on row 4800\n",
      "Working on row 4900\n",
      "Working on row 5000\n",
      "Working on row 5100\n",
      "Working on row 5200\n",
      "Working on row 5300\n",
      "Working on row 5400\n",
      "Working on row 5500\n",
      "Working on row 5600\n",
      "Working on row 5700\n",
      "Working on row 5800\n",
      "Working on row 5900\n",
      "Working on row 6000\n",
      "Working on row 6100\n",
      "Working on row 6200\n",
      "Working on row 6300\n",
      "Working on row 6400\n",
      "Working on row 6500\n",
      "Working on row 6600\n",
      "Working on row 6700\n",
      "Working on row 6800\n",
      "Working on row 6900\n",
      "Working on row 7000\n",
      "Working on row 7100\n",
      "Working on row 7200\n",
      "Working on row 7300\n",
      "Working on row 7400\n",
      "Working on row 7500\n",
      "Working on row 7600\n",
      "Working on row 7700\n",
      "Working on row 7800\n",
      "Working on row 7900\n",
      "Working on row 8000\n",
      "Working on row 8100\n",
      "Working on row 8200\n",
      "Working on row 8300\n",
      "Working on row 8400\n",
      "Working on row 8500\n",
      "Working on row 8600\n",
      "Working on row 8700\n",
      "Working on row 8800\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for i in range(neg_n):\n",
    "    if (i + 1)%100 == 0:\n",
    "        print(\"Working on row\", i + 1)\n",
    "    text = None\n",
    "    while True:\n",
    "        text = neg_df.iloc[idx]['text of the tweet']\n",
    "        # text = re.sub(r\"^(@\\w+\\s+)+\", \"\", text)\n",
    "        if text.strip() == \"\" or text in all_text:\n",
    "            idx += 1\n",
    "            continue\n",
    "        if get_sentiment(text) == 'negative':\n",
    "            idx += 1\n",
    "            break\n",
    "        else:\n",
    "            idx += 1\n",
    "            continue\n",
    "    df.loc[len(df)] = [text, 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d830ac7b-bcfa-4aa3-b01c-26e131c9b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"additional_ds.csv\", encoding=\"latin1\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c84e50-2162-473d-91b5-d5d11bd77fee",
   "metadata": {},
   "source": [
    "# Get more neutral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cffc01ff-004e-4b26-8fe7-83ef98c51866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deep_translator import GoogleTranslator\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e47f1-e6f9-4d5e-a0b8-7bd2665afc5e",
   "metadata": {},
   "source": [
    "## Back translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b437a079-c29b-449d-90bc-6a8fbf45a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translation(text, src_lang=\"en\", mid_lang=\"fr\"):\n",
    "    translated = GoogleTranslator(source=src_lang, target=mid_lang).translate(text)\n",
    "    back_translated = GoogleTranslator(source=mid_lang, target=src_lang).translate(translated)\n",
    "    return back_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1eebc5f-3c92-4d9e-b3ea-59467f92f2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would have answered, if I was going'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_translation('I`d have responded, if I were going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f40561c0-e84d-4d98-a600-d9a3600c774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.dothebouncy.com/smf - a little shameless taking for the forum of the best rangers on earth'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_translation('http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7336d32c-12dd-43fc-ba71-6ebdac11f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neu_df = tsad_df[tsad_df['sentiment'] == 'neutral'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "737d4c20-5ab5-427e-be6a-0368bf74a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_neu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa727a9f-4b12-41de-990a-1a62b4960a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on row 100\n",
      "Working on row 200\n",
      "Working on row 300\n",
      "Working on row 400\n",
      "Working on row 500\n",
      "Working on row 600\n",
      "Working on row 700\n",
      "Working on row 800\n",
      "Working on row 900\n",
      "Working on row 1000\n",
      "Working on row 1100\n",
      "Working on row 1200\n",
      "Working on row 1300\n",
      "Working on row 1400\n",
      "Working on row 1500\n",
      "Working on row 1600\n",
      "Working on row 1700\n",
      "Working on row 1800\n",
      "Working on row 1900\n",
      "Working on row 2000\n",
      "Working on row 2100\n",
      "Working on row 2200\n",
      "Working on row 2300\n",
      "Working on row 2400\n",
      "Working on row 2500\n",
      "Working on row 2600\n",
      "Working on row 2700\n",
      "Working on row 2800\n",
      "Working on row 2900\n",
      "Working on row 3000\n",
      "Working on row 3100\n",
      "Working on row 3200\n",
      "Working on row 3300\n",
      "Working on row 3400\n",
      "Working on row 3500\n",
      "Working on row 3600\n",
      "Working on row 3700\n",
      "Working on row 3800\n",
      "Working on row 3900\n",
      "Working on row 4000\n",
      "Working on row 4100\n",
      "Working on row 4200\n",
      "Working on row 4300\n",
      "Working on row 4400\n",
      "Working on row 4500\n",
      "Working on row 4600\n",
      "Working on row 4700\n",
      "Working on row 4800\n",
      "Working on row 4900\n",
      "Working on row 5000\n",
      "Working on row 5100\n",
      "Working on row 5200\n",
      "Working on row 5300\n",
      "Working on row 5400\n",
      "Working on row 5500\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for i in range(neu_n):\n",
    "    if (i + 1)%100 == 0:\n",
    "        print(\"Working on row\", i + 1)\n",
    "    text = None\n",
    "    while True:\n",
    "        og_text = neu_df.iloc[idx]['text']\n",
    "        try:\n",
    "            text = back_translation(og_text)\n",
    "            if text in all_text or text in new_neu:\n",
    "                idx += 1\n",
    "                continue\n",
    "            if get_sentiment(text) == 'neutral':\n",
    "                new_neu.append(text)\n",
    "                idx += 1\n",
    "                break\n",
    "            else:\n",
    "                idx += 1\n",
    "                continue\n",
    "        except Exception as e: \n",
    "            idx += 1\n",
    "            continue\n",
    "    df.loc[len(df)] = [text, 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbbaef-b677-4c5d-a187-dd13af80ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1687a0b2-cd93-4eff-b51c-492cb11f50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"additional_ds.csv\", encoding=\"latin1\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d1b9af-4f3a-44ce-9e0e-81161592966e",
   "metadata": {},
   "source": [
    "## Synonym replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e95d4-29b9-4d36-8a39-2dd5b14eb7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31e737-b2b6-405e-a3a8-20014a041c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "for w in stopwords.words('english'):\n",
    "    stop_words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af81157-3ef7-49f5-959a-c337ef9e048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    \n",
    "    synonyms = set()\n",
    "    \n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "            synonyms.add(synonym) \n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    \n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab6667-6935-4ef4-9733-41b9e18d4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replacement(words):\n",
    "    \n",
    "    words = words.split()\n",
    "    \n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if word not in stop_words]))\n",
    "    n = random.randint(1, len(random_word_list))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    \n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        \n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(list(synonyms))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        \n",
    "        if num_replaced >= n: #only replace up to n words\n",
    "            break\n",
    "\n",
    "    sentence = ' '.join(new_words)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45c7a6-1918-490a-b606-7a20ec1a10d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_replacement('http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248",
   "language": "python",
   "name": "cs4248"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
