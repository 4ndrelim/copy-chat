{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f4ab23a-5cba-49d0-b34e-f371baefa003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import json\n",
    "import uuid\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9adbf1-329b-43e5-b6cc-d73ab09e1bd8",
   "metadata": {},
   "source": [
    "# Loading train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b0aaec2-7fcd-4a1a-879b-c6a472af49db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Encoding: ISO-8859-1\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "file_path = \"train.csv\" \n",
    "\n",
    "with open(file_path, \"rb\") as f:\n",
    "    raw_data = f.read(100000) \n",
    "    result = chardet.detect(raw_data)\n",
    "\n",
    "print(f\"Detected Encoding: {result['encoding']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c53a4a38-4009-4f15-9bce-0e5eca1b13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"train.csv\"  \n",
    "df = pd.read_csv(file_path, usecols=['textID', 'text', 'sentiment'], encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "627f3729-6f1a-45e1-bbe8-c5f24e9ed852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  cb774db0d1                I`d have responded, if I were going   neutral\n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2  088c60f138                          my boss is bullying me...  negative\n",
       "3  9642c003ef                     what interview! leave me alone  negative\n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...  negative"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "066a20d3-a019-42b7-bb25-52a5043080d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27480"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c1ac0-8a9c-4391-8c7c-26725269519a",
   "metadata": {},
   "source": [
    "# Checking for duplicate values in textID and text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12fd4a8d-c6b1-49da-8323-d8b43e05fe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate textIDs: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_textID_count = df['textID'].duplicated().sum()\n",
    "print(f\"Number of duplicate textIDs: {duplicate_textID_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36de8b86-c070-41b8-ba18-49dea96e3741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate text values: 0\n"
     ]
    }
   ],
   "source": [
    "\\duplicate_text_count = df['text'].duplicated().sum()\n",
    "print(f\"Number of duplicate text values: {duplicate_text_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540784f1-74a0-46c7-b252-9e881759decb",
   "metadata": {},
   "source": [
    "# Checking for missing values in text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8417a964-7b4e-4734-abc0-22a7e1e0dbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'text': 1\n",
      "Number of empty text entries: 0\n"
     ]
    }
   ],
   "source": [
    "missing_text_count = df['text'].isna().sum()\n",
    "print(f\"Number of missing values in 'text': {missing_text_count}\")\n",
    "\n",
    "empty_text_count = (df['text'].str.strip() == '').sum()\n",
    "print(f\"Number of empty text entries: {empty_text_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c5cba08-7905-41ba-b994-95aa0dddd235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing text:\n",
      "         textID text sentiment\n",
      "314  fdb77c3752  NaN   neutral\n"
     ]
    }
   ],
   "source": [
    "missing_text_rows = df[df['text'].isna()]\n",
    "\n",
    "print(\"Rows with missing text:\")\n",
    "print(missing_text_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fa1840f-58dc-4f30-be5e-28c4639127eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9105e87-5611-455f-ab05-769c96d4c53b",
   "metadata": {},
   "source": [
    "# Making sure that there are only 3 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "668bf737-b248-49d5-90a5-5189ca0ab22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989894e-e81b-460e-a48d-d6aaf2f7bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.drop(['textID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21999c34-188c-4893-a72c-a52b927fe1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv(\"train_vanilla.csv\", encoding=\"latin1\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80768d21-4cde-4734-984b-b3957f11b35e",
   "metadata": {},
   "source": [
    "# Using cleanlab to check for wrong labels (using a simple logistic regression model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08a97a9a-de3d-4b47-8286-f43b35c0b0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_31512\\2487406335.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment_label'] = df['sentiment'].map(sentiment_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Convert sentiment labels to numerical values\n",
    "sentiment_mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "df['sentiment_label'] = df['sentiment'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf137892-d626-4bff-9374-28cb56a4ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])  \n",
    "y = df['sentiment_label'].values         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d632fda-2578-4f28-8981-a245f7c96ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "pred_probs = cross_val_predict(clf, X, y, cv=5, method=\"predict_proba\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b038dead-95da-4057-9b45-1c82a9e5a04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shawn\\anaconda3\\envs\\cs4248\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_31512\\3691671995.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label_issue'] = label_issues\n"
     ]
    }
   ],
   "source": [
    "from cleanlab.filter import find_label_issues\n",
    "\n",
    "# Identify potential label errors\n",
    "label_issues = find_label_issues(y, pred_probs)\n",
    "\n",
    "# Add a column indicating potential label issues\n",
    "df['label_issue'] = label_issues\n",
    "\n",
    "# Show samples with potential label errors\n",
    "incorrect_labels = df[df['label_issue'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07a041d7-ccce-477d-a610-c789ac2c1cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential label issues:        is_label_issue  label_quality  given_label  predicted_label  \\\n",
      "0               False       0.689745            1                1   \n",
      "1               False       0.931146            0                0   \n",
      "2               False       0.441509            0                1   \n",
      "3               False       0.456421            0                0   \n",
      "4                True       0.314842            0                1   \n",
      "...               ...            ...          ...              ...   \n",
      "27475           False       0.547392            0                0   \n",
      "27476            True       0.196894            0                1   \n",
      "27477           False       0.951319            2                2   \n",
      "27478           False       0.572459            2                2   \n",
      "27479           False       0.422144            1                2   \n",
      "\n",
      "       sample_weight  \n",
      "0           1.448187  \n",
      "1           1.246797  \n",
      "2           1.246797  \n",
      "3           1.246797  \n",
      "4           0.000000  \n",
      "...              ...  \n",
      "27475       1.246797  \n",
      "27476       0.000000  \n",
      "27477       1.134017  \n",
      "27478       1.134017  \n",
      "27479       1.448187  \n",
      "\n",
      "[27480 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from cleanlab.classification import CleanLearning\n",
    "clf = CleanLearning(LogisticRegression(max_iter=1000))\n",
    "clf.fit(X, y)\n",
    "\n",
    "label_issues = clf.get_label_issues()\n",
    "print(\"Potential label issues:\", label_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01da27d8-ee8e-4121-a8c2-f0a17c1f82d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>sample_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.314842</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>0.311513</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>0.214343</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>0.223929</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "      <td>0.193927</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27462</th>\n",
       "      <td>True</td>\n",
       "      <td>0.379187</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27469</th>\n",
       "      <td>True</td>\n",
       "      <td>0.150957</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27471</th>\n",
       "      <td>True</td>\n",
       "      <td>0.179836</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27473</th>\n",
       "      <td>True</td>\n",
       "      <td>0.199770</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>True</td>\n",
       "      <td>0.196894</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6047 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_label_issue  label_quality  given_label  predicted_label  \\\n",
       "4                True       0.314842            0                1   \n",
       "5                True       0.311513            1                2   \n",
       "12               True       0.214343            0                1   \n",
       "16               True       0.223929            0                1   \n",
       "17               True       0.193927            0                1   \n",
       "...               ...            ...          ...              ...   \n",
       "27462            True       0.379187            0                1   \n",
       "27469            True       0.150957            0                1   \n",
       "27471            True       0.179836            0                1   \n",
       "27473            True       0.199770            2                0   \n",
       "27476            True       0.196894            0                1   \n",
       "\n",
       "       sample_weight  \n",
       "4                0.0  \n",
       "5                0.0  \n",
       "12               0.0  \n",
       "16               0.0  \n",
       "17               0.0  \n",
       "...              ...  \n",
       "27462            0.0  \n",
       "27469            0.0  \n",
       "27471            0.0  \n",
       "27473            0.0  \n",
       "27476            0.0  \n",
       "\n",
       "[6047 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_issues[label_issues[\"is_label_issue\"] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61e6aa0-136c-49fb-a049-914c246c55bd",
   "metadata": {},
   "source": [
    "# Using a HF model to check for wrong labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a79b13b-4575-41ea-adf4-a759bc9772ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Load the model and tokenizer\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \n",
    "    encoded_input = tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    return config.id2label[ranking[0]].lower()\n",
    "\n",
    "df['predicted_sentiment'] = df['text'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35554f97-fb8c-4a3e-951b-51667b118588",
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabeled_df = df[df['predicted_sentiment'] != df['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ec4c938-7338-4f6c-95d8-4a4082e4be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"train_comparison_result.csv\", encoding=\"latin1\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "232e832f-fd6b-4155-8204-2444e6b1c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabeled_df = mislabeled_df.drop(['sentiment_label', 'label_issue'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "400b3c48-7cf2-41f5-8da1-d146cf8c2fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabeled sentiment data saved as mislabeled_sentiment.csv!\n"
     ]
    }
   ],
   "source": [
    "mislabeled_df.to_csv(\"mislabeled_sentiment.csv\", encoding=\"latin1\", index=False)\n",
    "print(\"Mislabeled sentiment data saved as mislabeled_sentiment.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c293daa7-f3c4-49c7-85e3-ec5549ea5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.drop(['textID','sentiment_label', 'label_issue', 'sentiment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "44e308e6-44d6-4ae8-8abd-0b4cd156e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.rename(columns={\"predicted_sentiment\": \"sentiment\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c8217bc9-71d1-43b4-ba7f-fcc12f70b4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0                I`d have responded, if I were going   neutral\n",
       "1      Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2                          my boss is bullying me...  negative\n",
       "3                     what interview! leave me alone  negative\n",
       "4   Sons of ****, why couldn`t they put them on t...  negative"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7af7575f-39f5-4223-a733-dd8cb5d28de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv(\"train_clean.csv\", encoding=\"latin1\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdffb47-484e-4c6f-9e39-64488a6cdc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248",
   "language": "python",
   "name": "cs4248"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
